{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586a2cfd",
   "metadata": {},
   "source": [
    "# Modeling Knowledge\n",
    "\n",
    "Terminology inspired by Hardt and Recht.\n",
    "\n",
    "## Generalization\n",
    "\n",
    "We start by an experiment. In Chapter [](ch:introduction) we very quickly built two classifiers. Let us now apply what we learned to the curious problem of determining whether someone is a \"cat person\" or a \"dog person\" by looking at a picture of their face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee64e49b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['axes.spines.top'] = 0\n",
    "mpl.rcParams['axes.spines.right'] = 0\n",
    "mpl.rcParams['axes.spines.left'] = 1\n",
    "mpl.rcParams['axes.spines.bottom'] = 1\n",
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178f8e25",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m5/k86qfx9j4sg7txgrjmpz2m3r0000gq/T/ipykernel_77621/1601703186.py\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mshuffle_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffle_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "image_size = (250, 250)\n",
    "scale = 0\n",
    "\n",
    "noise = np.zeros((2, *image_size))\n",
    "\n",
    "noise[0] = scale * np.random.randn(*image_size)\n",
    "noise[1] = scale * np.random.randn(*image_size)\n",
    "\n",
    "# noise[1] = -noise[0] # homework\n",
    "\n",
    "from pathlib import Path\n",
    "result = list(Path('./book_data/lfw/').rglob('*.jpg'))\n",
    "\n",
    "n_train = 1000\n",
    "n_test = 100\n",
    "images = np.zeros((n_train, 250, 250))\n",
    "labels = np.zeros((n_train,), dtype=np.int8)\n",
    "\n",
    "images_test = np.zeros((n_test, 250, 250))\n",
    "labels_test = np.zeros((n_test,), dtype=np.int8)\n",
    "\n",
    "shuffle_idx = np.random.permutation(n_train + n_test)\n",
    "for i in range(n_train):\n",
    "    images[i] = plt.imread(result[shuffle_idx[i]]).mean(axis=2)\n",
    "    labels[i] = np.round(np.random.rand())\n",
    "    images[i] += noise[labels[i]]\n",
    "\n",
    "for i in range(n_train, n_train + n_test):\n",
    "    images_test[i - n_train] = plt.imread(result[shuffle_idx[i]]).mean(axis=2)\n",
    "    labels_test[i - n_train] = np.round(np.random.rand())\n",
    "    # no noise in the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43617c",
   "metadata": {},
   "source": [
    "The interested customer has provided us with both a _training_ set and a _test_ set we can use to evaluate our method. Let's have a look at a couple of random images from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plots = 3\n",
    "fig, axs = plt.subplots(n_plots, n_plots, figsize=(10, 10))\n",
    "\n",
    "print(images.shape)\n",
    " \n",
    "text_label = ['dog', 'cat']\n",
    "for i in range(n_plots):\n",
    "    for j in range(n_plots):\n",
    "        axs[i, j].imshow(images[i*n_plots + j], cmap='gray');\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i, j].set_title(text_label[labels[i*n_plots + j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288e545",
   "metadata": {},
   "source": [
    "Who would have thought?\n",
    "\n",
    "Our next step is to use the code to fit a perceptron that we wrote last week. Instead of writing it again here we put it in a separate file and import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6210931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceptron import train\n",
    "\n",
    "labsym = labels*2 - 1\n",
    "w = train(images.reshape(n_train, -1), labsym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labsym_est = np.sign(images.reshape(n_train, -1) @ w)\n",
    "labels_est = np.int8((labsym_est + 1) / 2)\n",
    "n_correct = np.sum(labsym_est == labsym)\n",
    "print('The perceptron correctly classifies %d out of %d training images' % (n_correct, n_train))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "source_map": [
   14,
   24,
   38,
   74,
   81,
   93,
   99,
   107
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}